{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trained model for story generator - using the gpt_2_simple\n",
    "## Forked the original github repo to my repo - https://github.com/rbewoor/gpt-2-simple\n",
    "\n",
    "## Anaconda environment setup as follows:\n",
    "#\t*** create new environment\n",
    "#conda create -n --newENV python=3.7\n",
    "#\n",
    "#\t*** general stuff\n",
    "#conda install jupyter\n",
    "#\n",
    "#\t*** Story Generation\n",
    "#conda install numpy\n",
    "#conda install requests\n",
    "#conda install regex\n",
    "#pip install tensorflow==1.15.2\n",
    "#** not done this so far pip install toposort\n",
    "#pip install gpt-2-simple\t\t\t## Successfully installed gpt-2-simple-0.7.1 regex-2020.10.23 toposort-1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import gpt_2_simple as gpt2\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpt_2_simple.src import model, sample, encoder, memory_saving_gradients\n",
    "from gpt_2_simple.src.load_dataset import load_dataset, Sampler\n",
    "from gpt_2_simple.src.accumulate import AccumulatingOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.__version__ < '2.0.0', \"gpt-2-simple currently does not support \" \\\n",
    "    \"TensorFlow 2.0. You'll need to use a virtualenv/cloud computer which \" \\\n",
    "    \"has Tensorflow 1.X on it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "## -------------------     STORY GENERATOR STARTS                  STORY GENERATOR STARTS   -------------------\n",
    "###############################################################################################################\n",
    "def my_load_gpt2(_sess,\n",
    "              _checkpoint='latest',\n",
    "              _run_name=\"run1\",\n",
    "              _checkpoint_dir=\"checkpoint\",\n",
    "              _model_name=None,\n",
    "              _model_dir='models',\n",
    "              _multi_gpu=False):\n",
    "    \"\"\"Loads the model checkpoint or existing model into a TensorFlow session for repeated predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    if _model_name:\n",
    "        checkpoint_path = os.path.join(_model_dir, _model_name)\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(_checkpoint_dir, _run_name)\n",
    "    print(f\"\\ncheckpoint_path = {checkpoint_path}\\n\")\n",
    "\n",
    "    hparams = model.default_hparams()\n",
    "    with open(os.path.join(checkpoint_path, 'hparams.json')) as f:\n",
    "        hparams.override_from_dict(json.load(f))\n",
    "\n",
    "    context = tf.compat.v1.placeholder(tf.int32, [1, None])\n",
    "\n",
    "    gpus = []\n",
    "    if _multi_gpu:\n",
    "        gpus = get_available_gpus()\n",
    "\n",
    "    output = model.model(hparams=hparams, X=context, gpus=gpus)\n",
    "\n",
    "    if _checkpoint=='latest':\n",
    "        ckpt = tf.train.latest_checkpoint(checkpoint_path)\n",
    "    else:\n",
    "        ckpt = os.path.join(checkpoint_path,_checkpoint)\n",
    "\n",
    "    saver = tf.compat.v1.train.Saver(allow_empty=True)\n",
    "    _sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    if _model_name:\n",
    "        print(f\"\\nLoading pretrained model :: {ckpt}\\n\")\n",
    "    else:\n",
    "        print(f\"\\nLoading checkpoint :: {ckpt}\\n\")\n",
    "    saver.restore(_sess, ckpt)\n",
    "\n",
    "def reset_session(_sess, threads=-1, server=None):\n",
    "    \"\"\"Resets the current TensorFlow session, to clear memory\n",
    "    or load another model.\n",
    "    \"\"\"\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    _sess.close()\n",
    "\n",
    "def sty_gen_inference_functionality(_sg_params, _DEBUG_SWITCH):\n",
    "    _seed_for_styGen, SG_LENGTH, SG_TEMPERATURE, SG_NSAMPLES, SG_BATCH_SIZE, RUN_NAME, RETURN_LIST, DEST_PATH = _sg_params\n",
    "    \n",
    "    sty_gen_inference_module_results = []\n",
    "    \n",
    "    \n",
    "    ## set up the pre-trained GPT-2 model from checkpoint directory\n",
    "    \n",
    "    ## copy checkpoint directory from gdrive - not required as saved it locally\n",
    "    ##gpt2.copy_checkpoint_from_gdrive(run_name='run1')\n",
    "    GPT2_CHECKPOINT_DIR = r'/home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/'\n",
    "    #RUN_NAME = r\"run1\"\n",
    "\n",
    "    sess = gpt2.start_tf_sess()\n",
    "    print(f\"\\nTF session started\\n\")\n",
    "    #gpt2.load_gpt2(sess, run_name='run1')\n",
    "    my_load_gpt2(\n",
    "        _sess = sess,\n",
    "        _checkpoint='latest',\n",
    "        _run_name=RUN_NAME,\n",
    "        _checkpoint_dir=GPT2_CHECKPOINT_DIR,\n",
    "        _model_name=None,\n",
    "        _model_dir='models',\n",
    "        _multi_gpu=False)\n",
    "    \n",
    "    print(f\"\\n\\nGenerating the story using 'prefix' = {_seed_for_styGen}\\n\")\n",
    "    sty_gen_inference_module_results = gpt2.generate(\n",
    "        sess,\n",
    "        length=SG_LENGTH,\n",
    "        temperature=SG_TEMPERATURE,\n",
    "        prefix=seed_for_styGen,\n",
    "        nsamples=SG_NSAMPLES,\n",
    "        batch_size=SG_BATCH_SIZE,\n",
    "        checkpoint_dir=GPT2_CHECKPOINT_DIR,\n",
    "        return_as_list=RETURN_LIST,\n",
    "        destination_path=DEST_PATH\n",
    "    )\n",
    "    \n",
    "    reset_session(sess)\n",
    "    print(f\"\\n\\nFINISHED generating the story\\n\")\n",
    "    return sty_gen_inference_module_results\n",
    "\n",
    "###############################################################################################################\n",
    "## ---------------------     STORY GENERATOR ENDS                  STORY GENERATOR ENDS   ---------------------\n",
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF session started\n",
      "\n",
      "\n",
      "checkpoint_path = /home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/Run2_File11_2_checkpoint_run2\n",
      "\n",
      "\n",
      "Loading checkpoint :: /home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/Run2_File11_2_checkpoint_run2/model-17000\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/Run2_File11_2_checkpoint_run2/model-17000\n",
      "\n",
      "\n",
      "Generating the story using 'prefix' = Woman is sitting on couch with her cell phone.\n",
      "\n",
      "Woman is sitting on couch with her cell phone.\n",
      "She can be annoying -- she and her fashion.\n",
      "I wonder if she will have any idea -- no posture, or attitude whatever.\n",
      "Any way she is, her weight is such a troublesome thing to me.\n",
      "Every fine and dainty thing she asks me to lay down among it -- feet, arms, or books that I did not mind because I thought I would future for a horse, if I knew how to ride.\n",
      "She is a good advocate.\n",
      "Nothing frustrates her like my blemishes I have worn down my beard -- it was so smooth and soft, and she was so kind to me with them -- now she looks so stern and nosy.\n",
      "But she is never hurt herself -- but what do you think of it?\n",
      "I could hate her . ''\n",
      "Anne closed her cell phone and looked out on the plain, brooding sunshine.\n",
      "Plucked wind and heather in the clear air dovetailed in her eye as she ran in and sat down on the bare mattress in the beach.\n",
      "The weather rose suddenly, as a wave lifted her out of her bed ; for it had taken up the denim with its corks, covered her with thereabouts ... and her hair against the damp yell had covered her with the gaud of sunlight.\n",
      "Being a sea-stalk, excited, and sore, she felt tired to death.\n",
      "She stole her seat to the old bed.\n",
      "`` I wanted to see her tomorrow,\n",
      "\n",
      "\n",
      "FINISHED generating the story\n",
      "\n",
      "\n",
      "type = <class 'NoneType'>\n",
      "\n",
      "Output =\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Parameters to generate the story\n",
    "## NOTE: nsamples % batch_size == 0\n",
    "SG_LENGTH = 300\n",
    "SG_TEMPERATURE = 0.95\n",
    "SG_NSAMPLES = 1\n",
    "SG_BATCH_SIZE = 1\n",
    "RUN_NAME = r\"Run2_File11_2_checkpoint_run2\"\n",
    "RETURN_LIST = False\n",
    "DEST_PATH = None\n",
    "DEBUG_SWITCH = False\n",
    "\n",
    "## seed value - story 6\n",
    "seed_for_styGen = r'Woman is sitting on couch with her cell phone.'\n",
    "\n",
    "## check samples and batch size values are compatible\n",
    "assert (SG_NSAMPLES % SG_BATCH_SIZE == 0) , f\"Values for NSAMPLES and BATCH_SIZE incompatible. \" \\\n",
    "        f\"NSAMPLES={SG_NSAMPLES} % SG_BATCH_SIZE={SG_BATCH_SIZE} != 0\"\n",
    "\n",
    "SG_PARAMS = (seed_for_styGen, SG_LENGTH, SG_TEMPERATURE, SG_NSAMPLES, SG_BATCH_SIZE, RUN_NAME, RETURN_LIST, DEST_PATH)\n",
    "\n",
    "story_text = sty_gen_inference_functionality(SG_PARAMS, DEBUG_SWITCH)\n",
    "\n",
    "print(f\"\\ntype = {type(story_text)}\\n\\nOutput =\\n{story_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF session started\n",
      "\n",
      "\n",
      "checkpoint_path = /home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/Run2_File11_2_checkpoint_run2\n",
      "\n",
      "\n",
      "Loading checkpoint :: /home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/Run2_File11_2_checkpoint_run2/model-17000\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/rohit/PyWDUbuntu/thesis/StyGen/checkpoint/Run2_File11_2_checkpoint_run2/model-17000\n",
      "\n",
      "\n",
      "Generating the story using 'prefix' = Young boy standing in front of tv playing video game.\n",
      "\n",
      "Young boy standing in front of tv playing video game.\n",
      "Sammy broke his way down up to his room and devoured everything in to take the dare.\n",
      "Then he began to sing with a beaming voice.\n",
      "`` Let the boy go and play with Reddy Fox ! ''\n",
      "`` What da -- forget it, Sammy Brown ! ''\n",
      "cried Reddy Fox.\n",
      "`` Sammy Brown is a man that can not be leavin ' the Green Meadows alone . ''\n",
      "That was not to Sammy Brown, though he knew it.\n",
      "They were all afraid, even the ones to his face like Sammy.\n",
      "Sammy had been looking out for Reddy Fox for ages.\n",
      "It was never been his custom to do so, because he commanded the younger Sams in Old Mother Ned 's guesthouse.\n",
      "He used to climb into a box, and do whatever was necessary to rot down and earn in the hole he saw through the window.\n",
      "I do not doubt that when Sammy Brown made that cruel claim and threw him in full flight, that he was very followed.\n",
      "This definitely did not show, though!\n",
      "As he was dismounting this people, Reddy Fox pulled down the rabbit and held it up in his voice.\n",
      "He would heard Sammy Brown 's claim that he would be one of the mustangs when he grew up.\n",
      "Sammy was ever so much bigger than alive, but he was not such an easy-going fellow as Sammy Brown, so he hardly dared to give him such\n",
      "\n",
      "\n",
      "FINISHED generating the story\n",
      "\n",
      "\n",
      "type = <class 'NoneType'>\n",
      "\n",
      "Output =\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Parameters to generate the story\n",
    "## NOTE: nsamples % batch_size == 0\n",
    "SG_LENGTH = 300\n",
    "SG_TEMPERATURE = 0.95\n",
    "SG_NSAMPLES = 1\n",
    "SG_BATCH_SIZE = 1\n",
    "RUN_NAME = r\"Run2_File11_2_checkpoint_run2\"\n",
    "RETURN_LIST = False\n",
    "DEST_PATH = None\n",
    "DEBUG_SWITCH = False\n",
    "\n",
    "## seed value - story 6\n",
    "seed_for_styGen = r'Young boy standing in front of tv playing video game.'\n",
    "\n",
    "## check samples and batch size values are compatible\n",
    "assert (SG_NSAMPLES % SG_BATCH_SIZE == 0) , f\"Values for NSAMPLES and BATCH_SIZE incompatible. \" \\\n",
    "        f\"NSAMPLES={SG_NSAMPLES} % SG_BATCH_SIZE={SG_BATCH_SIZE} != 0\"\n",
    "\n",
    "SG_PARAMS = (seed_for_styGen, SG_LENGTH, SG_TEMPERATURE, SG_NSAMPLES, SG_BATCH_SIZE, RUN_NAME, RETURN_LIST, DEST_PATH)\n",
    "\n",
    "story_text = sty_gen_inference_functionality(SG_PARAMS, DEBUG_SWITCH)\n",
    "\n",
    "print(f\"\\ntype = {type(story_text)}\\n\\nOutput =\\n{story_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
